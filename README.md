# Automated Multimodal System For Holistic Answer Sheet Evaluation
This project implements a multimodal answer sheet evaluation approach that combines both textual and visual analysis for enhanced accuracy. Textual responses are evaluated using NLP techniques powered by a fine-tuned LLaMA 3.2 large language model, enabling contextual understanding, key point prioritization, and flexible answer structures. For diagram evaluation, the system integrates LightGlue, a deep learning framework, supported by a custom image preprocessing pipeline. OCR is used to extract diagram labels, which are then analyzed using NLP metrics to assess label relevance and improve diagram feature evaluation accuracy.
